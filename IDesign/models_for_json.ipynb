{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9c5261",
   "metadata": {},
   "source": [
    "### Check paths, versions and gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8353477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] = \"/home/jovyan/miniconda3/envs/idesign_env/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf33936",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ee481d-5be1-4c83-9ba6-64b4cbabaff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/home/jovyan/shares/SR006.nfs2/Kulichenko/Design_Iana\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a23b6e-ca83-439e-a0d9-ccb804d81aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!CUDA_HOME=/home/jovyan/cuda-11.8 \\\n",
    "CUDA_TOOLKIT_ROOT_DIR=/home/jovyan/cuda-11.8 \\\n",
    "PATH=/home/jovyan/cuda-11.8/bin:$PATH \\\n",
    "LD_LIBRARY_PATH=/home/jovyan/cuda-11.8/lib64:$LD_LIBRARY_PATH \\\n",
    "CMAKE_ARGS=\"-DGGML_CUDA=on \\\n",
    "            -DCUDA_TOOLKIT_ROOT_DIR=/home/jovyan/cuda-11.8 \\\n",
    "            -Wno-dev\" \\\n",
    "nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320feabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/bin/python\n",
      "Python 3.10.16\n",
      "Name: torch\n",
      "Version: 2.4.0+cu118\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu11, nvidia-cuda-cupti-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11, nvidia-cufft-cu11, nvidia-curand-cu11, nvidia-cusolver-cu11, nvidia-cusparse-cu11, nvidia-nccl-cu11, nvidia-nvtx-cu11, sympy, triton, typing-extensions\n",
      "Required-by: accelerate, bitsandbytes, compressed-tensors, dgl, MinkowskiEngine, outlines, timm, torchaudio, torchvision, vllm-flash-attn, xformers, xgrammar\n",
      "Name: torchvision\n",
      "Version: 0.19.0+cu118\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages\n",
      "Requires: numpy, pillow, torch\n",
      "Required-by: timm\n",
      "Name: torchaudio\n",
      "Version: 2.1.1\n",
      "Summary: An audio package for PyTorch\n",
      "Home-page: https://github.com/pytorch/audio\n",
      "Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n",
      "Author-email: soumith@pytorch.org\n",
      "License: \n",
      "Location: /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages\n",
      "Requires: torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version\n",
    "!pip show torch\n",
    "!pip show torchvision\n",
    "!pip show torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae3aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU Name: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)  \n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "031bce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 20 17:14:01 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:57:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              77W / 400W |   3168MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000000:9E:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              76W / 400W |   2812MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     12194      C   python                                     3160MiB |\n",
      "|    1   N/A  N/A     12194      C   python                                     2804MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5078814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CUDA_HOME=/home/jovyan/cuda-11.8\n",
    "# export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME\n",
    "# export PATH=$CUDA_HOME/bin:$PATH\n",
    "# export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH\n",
    "# export CC=/usr/bin/gcc\n",
    "# export CXX=/usr/bin/g++\n",
    "# export LDFLAGS=\"-L${CONDA_PREFIX}/lib \\\n",
    "#                -L/lib/x86_64-linux-gnu \\\n",
    "#                -L/usr/lib/x86_64-linux-gnu \\\n",
    "#                $LDFLAGS\"\n",
    "\n",
    "# CUDA_HOME=$CUDA_HOME \\\n",
    "# CUDA_TOOLKIT_ROOT_DIR=$CUDA_TOOLKIT_ROOT_DIR \\\n",
    "# PATH=$PATH \\\n",
    "# LD_LIBRARY_PATH=$LD_LIBRARY_PATH \\\n",
    "# LDFLAGS=\"$LDFLAGS\" \\\n",
    "# CMAKE_ARGS=\"-DGGML_CUDA=on \\\n",
    "#             -DCUDA_TOOLKIT_ROOT_DIR=$CUDA_TOOLKIT_ROOT_DIR \\\n",
    "#             -Wno-dev\" \\\n",
    "# pip install llama-cpp-python \\\n",
    "#   --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1558b525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu118\n",
      "Requirement already satisfied: llama-cpp-python in /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages (0.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!CMAKE_ARGS=\"-DGGML_CUDA=on -Wno-dev\" pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f0df64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.25\n",
      "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.25 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6e4475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No broken requirements found.\n"
     ]
    }
   ],
   "source": [
    "!pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5b8a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pkill -f python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "494d4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /home/jovyan/miniconda3/envs/idesign_env/lib/python3.9/site-packages/~umpy.libs\n",
    "# !rm -rf /home/jovyan/miniconda3/envs/idesign_env/lib/python3.9/site-packages/~umpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8d49059",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydantic==1.10.15 langfuse langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68fad3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "158ecf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4101cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --pre guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9390b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "Downloading 'mistral-7b-v0.1.Q4_K_M.gguf' to '.cache/huggingface/download/rAdFtzyS6dBYqo0ywrkBjjqajgw=.ce6253d2e91adea0c35924b38411b0434fa18fcb90c52980ce68187dbcbbe40c.incomplete'\n",
      "mistral-7b-v0.1.Q4_K_M.gguf: 100%|█████████| 4.37G/4.37G [01:00<00:00, 71.7MB/s]\n",
      "Download complete. Moving file to mistral-7b-v0.1.Q4_K_M.gguf\n",
      "mistral-7b-v0.1.Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download TheBloke/Mistral-7B-v0.1-GGUF mistral-7b-v0.1.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3229f3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shares/SR006.nfs2/miniconda/envs/idesign/lib/python3.10/site-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "Downloading 'mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf' to '.cache/huggingface/download/UCUfWi_O4tURLsT5lguByywrQeQ=.825931d483b408f104679764b8a0f00f45cee3c9f2d5632bb28ecf56d932ccae.incomplete'\n",
      "(…)ral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf: 100%|█| 5.13G/5.13G [01:10<00:00, 7\n",
      "Download complete. Moving file to mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf\n",
      "mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-code-ft-GGUF mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf --local-dir . --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53f4b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-code-ft-GGUF mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf --local-dir . --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a325f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli download TheBloke/CodeLlama-70B-Instruct-GGUF --filename codellama-70b-instruct.Q4_K_M.gguf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78d8aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                                                                          Size  Used Avail Use% Mounted on\n",
      "pd11-nfs.sr002.aicloud.sbercloud.tech:/vol_fg1/namespace_ai0001053-01306/workspace  500G  119G  382G  24% /home/jovyan\n"
     ]
    }
   ],
   "source": [
    "!df -h /home/jovyan/Kulichenko/IDesign/IDesign_Iana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c81a8-cbf2-4f0f-8a4d-4deb630d364d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb9101a",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13a7f136-9f16-4a17-9453-588388252ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "542b27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_cpp import Llama\n",
    "# import json\n",
    "# from jsonschema import validate, ValidationError\n",
    "\n",
    "# # Load the model\n",
    "# lm = Llama.from_pretrained(\n",
    "#     repo_id=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "#     filename=\"mistral-7b-instruct-v0.1.Q8_0.gguf\",\n",
    "#     n_gpu_layers=-1,  # Enables all layers on GPU\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea3e65",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f398da6",
   "metadata": {},
   "source": [
    "### Llama cpp and  mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ec15415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6d57326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 2 CUDA devices:\n",
      "  Device 0: NVIDIA A100-SXM4-80GB, compute capability 8.0, VMM: yes\n",
      "  Device 1: NVIDIA A100-SXM4-80GB, compute capability 8.0, VMM: yes\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA A100-SXM4-80GB) - 77462 MiB free\n",
      "llama_model_load_from_file_impl: using device CUDA1 (NVIDIA A100-SXM4-80GB) - 77818 MiB free\n",
      "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from ./mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = nondzu_mistral-7b-instruct-v0.2-code-ft\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q5_K - Medium\n",
      "print_info: file size   = 4.78 GiB (5.67 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = nondzu_mistral-7b-instruct-v0.2-code-ft\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CUDA0\n",
      "load_tensors: layer   1 assigned to device CUDA0\n",
      "load_tensors: layer   2 assigned to device CUDA0\n",
      "load_tensors: layer   3 assigned to device CUDA0\n",
      "load_tensors: layer   4 assigned to device CUDA0\n",
      "load_tensors: layer   5 assigned to device CUDA0\n",
      "load_tensors: layer   6 assigned to device CUDA0\n",
      "load_tensors: layer   7 assigned to device CUDA0\n",
      "load_tensors: layer   8 assigned to device CUDA0\n",
      "load_tensors: layer   9 assigned to device CUDA0\n",
      "load_tensors: layer  10 assigned to device CUDA0\n",
      "load_tensors: layer  11 assigned to device CUDA0\n",
      "load_tensors: layer  12 assigned to device CUDA0\n",
      "load_tensors: layer  13 assigned to device CUDA0\n",
      "load_tensors: layer  14 assigned to device CUDA0\n",
      "load_tensors: layer  15 assigned to device CUDA0\n",
      "load_tensors: layer  16 assigned to device CUDA0\n",
      "load_tensors: layer  17 assigned to device CUDA1\n",
      "load_tensors: layer  18 assigned to device CUDA1\n",
      "load_tensors: layer  19 assigned to device CUDA1\n",
      "load_tensors: layer  20 assigned to device CUDA1\n",
      "load_tensors: layer  21 assigned to device CUDA1\n",
      "load_tensors: layer  22 assigned to device CUDA1\n",
      "load_tensors: layer  23 assigned to device CUDA1\n",
      "load_tensors: layer  24 assigned to device CUDA1\n",
      "load_tensors: layer  25 assigned to device CUDA1\n",
      "load_tensors: layer  26 assigned to device CUDA1\n",
      "load_tensors: layer  27 assigned to device CUDA1\n",
      "load_tensors: layer  28 assigned to device CUDA1\n",
      "load_tensors: layer  29 assigned to device CUDA1\n",
      "load_tensors: layer  30 assigned to device CUDA1\n",
      "load_tensors: layer  31 assigned to device CUDA1\n",
      "load_tensors: layer  32 assigned to device CUDA1\n",
      "load_tensors: tensor 'token_embd.weight' (q5_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 32 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 33/33 layers to GPU\n",
      "load_tensors:        CUDA0 model buffer size =  2495.28 MiB\n",
      "load_tensors:        CUDA1 model buffer size =  2311.77 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =    85.94 MiB\n",
      ".................................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 1024\n",
      "llama_init_from_model: n_ctx_per_seq = 1024\n",
      "llama_init_from_model: n_batch       = 1024\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 1000000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (1024) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 1024, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    68.00 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =    60.00 MiB\n",
      "llama_init_from_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
      "llama_init_from_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_init_from_model: pipeline parallelism enabled (n_copies=4)\n",
      "llama_init_from_model:      CUDA0 compute buffer size =   136.01 MiB\n",
      "llama_init_from_model:      CUDA1 compute buffer size =   136.02 MiB\n",
      "llama_init_from_model:  CUDA_Host compute buffer size =    16.02 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 3\n",
      "CUDA : ARCHS = 800 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'nondzu_mistral-7b-instruct-v0.2-code-ft', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "import torch\n",
    "\n",
    "n_gpu_layers = -1  \n",
    "n_batch = 1024\n",
    "\n",
    "lm = Llama(\n",
    "    model_path=\"./mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf\",\n",
    "    n_gpu_layers=-1,    \n",
    "    n_batch=1024,       \n",
    "    f16_kv=True,       \n",
    "    n_ctx=1024         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21de4a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "check_gpu_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2a903",
   "metadata": {},
   "source": [
    "#### for max tokens = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4df31c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     258.86 ms\n",
      "llama_perf_context_print: prompt eval time =     258.46 ms /   252 tokens (    1.03 ms per token,   975.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4770.80 ms /   511 runs   (    9.34 ms per token,   107.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5434.19 ms /   763 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model:\n",
      "{'id': 'chatcmpl-ef138eae-e29f-4c3d-9a92-0d07a52c8cc4', 'object': 'chat.completion', 'created': 1745158166, 'model': './mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': ' Here are four essential objects for a modern large living room:\\n\\n```JSON\\n{\\n    \"Objects\": [\\n        {\\n            \"Object name\": \"Modern Sectional Sofa\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"leather\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 3.0,\\n                \"Width\": 3.0,\\n                \"Height\": 1.0\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Minimalist Coffee Table\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"glass\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 2.0,\\n                \"Width\": 2.0,\\n                \"Height\": 0.5\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Industrial Floor Lamp\",\\n            \"Architecture style\": \"industrial\",\\n            \"Material\": \"metal\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 0.5,\\n                \"Width\": 0.5,\\n                \"Height\": 2.0\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Contemporary Rug\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"wool\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 4.0,\\n                \"Width\": 6.0,\\n                \"Height\": 0.1\\n            },\\n            \"Quantity\": 1\\n        }\\n    ]\\n}\\n```\\n\\nThis JSON includes a modern sectional sofa made of leather, a minimalist coffee table made of glass, an industrial floor lamp made of metal, and a contemporary rug made of wool. The dimensions of these objects are approximate and based on typical sizes for such items. You can adjust the size and quantity according to your specific needs.\\n\\nPlease note that the size of these objects has to be adjusted according to the actual size of the room. These objects might not fit in a room of dimensions 10'}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 252, 'completion_tokens': 512, 'total_tokens': 764}}\n",
      "Generated text:/n Here are four essential objects for a modern large living room:\n",
      "\n",
      "```JSON\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Modern Sectional Sofa\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 3.0,\n",
      "                \"Height\": 1.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Minimalist Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.0,\n",
      "                \"Width\": 2.0,\n",
      "                \"Height\": 0.5\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Industrial Floor Lamp\",\n",
      "            \"Architecture style\": \"industrial\",\n",
      "            \"Material\": \"metal\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 0.5,\n",
      "                \"Width\": 0.5,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Contemporary Rug\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wool\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 4.0,\n",
      "                \"Width\": 6.0,\n",
      "                \"Height\": 0.1\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON includes a modern sectional sofa made of leather, a minimalist coffee table made of glass, an industrial floor lamp made of metal, and a contemporary rug made of wool. The dimensions of these objects are approximate and based on typical sizes for such items. You can adjust the size and quantity according to your specific needs.\n",
      "\n",
      "Please note that the size of these objects has to be adjusted according to the actual size of the room. These objects might not fit in a room of dimensions 10\n",
      "Generated JSON is valid:\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Modern Sectional Sofa\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 3.0,\n",
      "                \"Height\": 1.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Minimalist Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.0,\n",
      "                \"Width\": 2.0,\n",
      "                \"Height\": 0.5\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Industrial Floor Lamp\",\n",
      "            \"Architecture style\": \"industrial\",\n",
      "            \"Material\": \"metal\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 0.5,\n",
      "                \"Width\": 0.5,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Contemporary Rug\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wool\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 4.0,\n",
      "                \"Width\": 6.0,\n",
      "                \"Height\": 0.1\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Generation took 0.01 seconds to complete.\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "import time\n",
    "\n",
    "design_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Objects\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Object name\": {\"type\": \"string\"},\n",
    "                    \"Architecture style\": {\"type\": \"string\", \"enum\": [\"modern\", \"traditional\", \"industrial\"]},\n",
    "                    \"Material\": {\"type\": \"string\"},\n",
    "                    \"Bounding box size in meters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"Length\": {\"type\": \"number\"},\n",
    "                            \"Width\": {\"type\": \"number\"},\n",
    "                            \"Height\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"Length\", \"Width\", \"Height\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"Quantity\": {\"type\": \"integer\", \"minimum\": 1}\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"Object name\", \"Architecture style\", \"Material\",\n",
    "                    \"Bounding box size in meters\", \"Quantity\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"Objects\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "test_prompt = \"\"\"\n",
    "Design a modern large living room with dimensions (10m x 10m x 6m). \n",
    "Suggest 4 essential objects based on the room size, style, and user needs.\n",
    "\n",
    "Respond with a JSON array of objects, each including:\n",
    "- \"Object name\"\n",
    "- \"Architecture style\" (modern, traditional, industrial)\n",
    "- \"Material\" (wood, metal, glass)\n",
    "- \"Bounding box size in meters\" (Length, Width, Height)\n",
    "- \"Quantity\"\n",
    "\n",
    "Respond strictly in the following JSON format:\n",
    "{\n",
    "    \"Objects\": [\n",
    "        {\n",
    "            \"Object name\": \"Sample Object\",\n",
    "            \"Architecture style\": \"modern\",\n",
    "            \"Material\": \"wood\",\n",
    "            \"Bounding box size in meters\": {\n",
    "                \"Length\": 1.0,\n",
    "                \"Width\": 1.0,\n",
    "                \"Height\": 1.0\n",
    "            },\n",
    "            \"Quantity\": 1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Ensure JSON format is complete and within token limits.\n",
    "\"\"\"\n",
    "\n",
    "response = lm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that outputs in JSON format.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": test_prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n",
    "print(\"Response from model:\")\n",
    "print(response)\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    generated_text = response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    print(f\"Generated text:/n{generated_text}\")\n",
    "    if not generated_text:\n",
    "        raise KeyError(\"'content' key not found in response\")\n",
    "    \n",
    "    # extract JSON content\n",
    "    start_index = generated_text.find('{')\n",
    "    end_index = generated_text.rfind('}') + 1\n",
    "    extracted_json_text = generated_text[start_index:end_index]\n",
    "\n",
    "    generated_json = json.loads(extracted_json_text)\n",
    "    validate(instance=generated_json, schema=design_schema)\n",
    "    print(\"Generated JSON is valid:\")\n",
    "    print(json.dumps(generated_json, indent=4))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Generation took {elapsed_time:.2f} seconds to complete.\")\n",
    "\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse as JSON\")\n",
    "except ValidationError as e:\n",
    "    print(\"Generated JSON is invalid:\")\n",
    "    print(e.message)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e371f77",
   "metadata": {},
   "source": [
    "#### for max tokens = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e628e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 251 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =     258.86 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    5286.44 ms /   566 runs   (    9.34 ms per token,   107.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5754.41 ms /   567 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model:\n",
      "{'id': 'chatcmpl-e7e27ff4-1364-454a-be99-a18d635f1a34', 'object': 'chat.completion', 'created': 1745158225, 'model': './mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': ' {\\n    \"Objects\": [\\n        {\\n            \"Object name\": \"Modern Coffee Table\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"glass and steel\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 1.8,\\n                \"Width\": 0.9,\\n                \"Height\": 0.45\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Contemporary Sofa Set\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"leather and wood\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 2.5,\\n                \"Width\": 1.2,\\n                \"Height\": 0.9\\n            },\\n            \"Quantity\": 2\\n        },\\n        {\\n            \"Object name\": \"Industrial Bookshelf\",\\n            \"Architecture style\": \"industrial\",\\n            \"Material\": \"metal and glass\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 3.0,\\n                \"Width\": 0.9,\\n                \"Height\": 2.0\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Minimalist Artwork\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"canvas and paint\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 0.9,\\n                \"Width\": 0.9,\\n                \"Height\": 2.0\\n            },\\n            \"Quantity\": 1\\n        }\\n    ]\\n}\\n\\nThis JSON array includes a modern coffee table made of glass and steel, a contemporary sofa set with leather and wood, an industrial bookshelf with metal and glass, and a minimalist artwork made of canvas and paint. The sizes of these objects have been chosen according to the average dimensions of similar items and the available space in a 10m x 10m x 6m room. The quantity for each object is set to 1, but can be adjusted according to the specific needs and preferences of the user. The bounding box dimensions are also estimates and may vary depending on the exact dimensions and design of each object. The chosen architecture styles and materials reflect a modern aesthetic, which is commonly preferred in large living spaces. However, the list could also include items in traditional or industrial styles according to different design preferences.'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 252, 'completion_tokens': 565, 'total_tokens': 817}}\n",
      "Generated text:/n {\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Modern Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass and steel\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.8,\n",
      "                \"Width\": 0.9,\n",
      "                \"Height\": 0.45\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Contemporary Sofa Set\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather and wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.5,\n",
      "                \"Width\": 1.2,\n",
      "                \"Height\": 0.9\n",
      "            },\n",
      "            \"Quantity\": 2\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Industrial Bookshelf\",\n",
      "            \"Architecture style\": \"industrial\",\n",
      "            \"Material\": \"metal and glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 0.9,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Minimalist Artwork\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"canvas and paint\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 0.9,\n",
      "                \"Width\": 0.9,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "This JSON array includes a modern coffee table made of glass and steel, a contemporary sofa set with leather and wood, an industrial bookshelf with metal and glass, and a minimalist artwork made of canvas and paint. The sizes of these objects have been chosen according to the average dimensions of similar items and the available space in a 10m x 10m x 6m room. The quantity for each object is set to 1, but can be adjusted according to the specific needs and preferences of the user. The bounding box dimensions are also estimates and may vary depending on the exact dimensions and design of each object. The chosen architecture styles and materials reflect a modern aesthetic, which is commonly preferred in large living spaces. However, the list could also include items in traditional or industrial styles according to different design preferences.\n",
      "Generated JSON is valid:\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Modern Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass and steel\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.8,\n",
      "                \"Width\": 0.9,\n",
      "                \"Height\": 0.45\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Contemporary Sofa Set\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather and wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.5,\n",
      "                \"Width\": 1.2,\n",
      "                \"Height\": 0.9\n",
      "            },\n",
      "            \"Quantity\": 2\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Industrial Bookshelf\",\n",
      "            \"Architecture style\": \"industrial\",\n",
      "            \"Material\": \"metal and glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 0.9,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Minimalist Artwork\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"canvas and paint\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 0.9,\n",
      "                \"Width\": 0.9,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Generation took 0.01 seconds to complete.\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "design_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Objects\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Object name\": {\"type\": \"string\"},\n",
    "                    \"Architecture style\": {\"type\": \"string\", \"enum\": [\"modern\", \"traditional\", \"industrial\"]},\n",
    "                    \"Material\": {\"type\": \"string\"},\n",
    "                    \"Bounding box size in meters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"Length\": {\"type\": \"number\"},\n",
    "                            \"Width\": {\"type\": \"number\"},\n",
    "                            \"Height\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"Length\", \"Width\", \"Height\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"Quantity\": {\"type\": \"integer\", \"minimum\": 1}\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"Object name\", \"Architecture style\", \"Material\",\n",
    "                    \"Bounding box size in meters\", \"Quantity\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"Objects\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "test_prompt = \"\"\"\n",
    "Design a modern large living room with dimensions (10m x 10m x 6m). \n",
    "Suggest 4 essential objects based on the room size, style, and user needs.\n",
    "\n",
    "Respond with a JSON array of objects, each including:\n",
    "- \"Object name\"\n",
    "- \"Architecture style\" (modern, traditional, industrial)\n",
    "- \"Material\" (wood, metal, glass)\n",
    "- \"Bounding box size in meters\" (Length, Width, Height)\n",
    "- \"Quantity\"\n",
    "\n",
    "Respond strictly in the following JSON format:\n",
    "{\n",
    "    \"Objects\": [\n",
    "        {\n",
    "            \"Object name\": \"Sample Object\",\n",
    "            \"Architecture style\": \"modern\",\n",
    "            \"Material\": \"wood\",\n",
    "            \"Bounding box size in meters\": {\n",
    "                \"Length\": 1.0,\n",
    "                \"Width\": 1.0,\n",
    "                \"Height\": 1.0\n",
    "            },\n",
    "            \"Quantity\": 1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Ensure JSON format is complete and within token limits.\n",
    "\"\"\"\n",
    "\n",
    "response = lm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that outputs in JSON format.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": test_prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024  \n",
    ")\n",
    "\n",
    "print(\"Response from model:\")\n",
    "print(response)\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    generated_text = response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    print(f\"Generated text:/n{generated_text}\")\n",
    "    if not generated_text:\n",
    "        raise KeyError(\"'content' key not found in response\")\n",
    "    \n",
    "    # extract JSON content\n",
    "    start_index = generated_text.find('{')\n",
    "    end_index = generated_text.rfind('}') + 1\n",
    "    extracted_json_text = generated_text[start_index:end_index]\n",
    "\n",
    "    generated_json = json.loads(extracted_json_text)\n",
    "    validate(instance=generated_json, schema=design_schema)\n",
    "    print(\"Generated JSON is valid:\")\n",
    "    print(json.dumps(generated_json, indent=4))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Generation took {elapsed_time:.2f} seconds to complete.\")\n",
    "\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse as JSON\")\n",
    "except ValidationError as e:\n",
    "    print(\"Generated JSON is invalid:\")\n",
    "    print(e.message)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce3e2e",
   "metadata": {},
   "source": [
    "### The JSON is valid and of good quality, but the response takes quite a bit of time to arrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca296e0",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae19558",
   "metadata": {},
   "source": [
    "### Using Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553a5e57-2130-40a3-ae2a-a10243784590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a807ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "from guidance import models, gen, select, json as gen_json\n",
    "\n",
    "design_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Objects\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Object name\": {\"type\": \"string\"},\n",
    "                    \"Architecture style\": {\"type\": \"string\", \"enum\": [\"modern\", \"traditional\", \"industrial\"]},\n",
    "                    \"Material\": {\"type\": \"string\", \"enum\": [\"wood\", \"metal\", \"glass\"]},\n",
    "                    \"Bounding box size in meters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"Length\": {\"type\": \"number\"},\n",
    "                            \"Width\": {\"type\": \"number\"},\n",
    "                            \"Height\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"Length\", \"Width\", \"Height\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"Quantity\": {\"type\": \"integer\", \"minimum\": 1}\n",
    "                },\n",
    "                \"required\": [\"Object name\", \"Architecture style\", \"Material\", \"Bounding box size in meters\", \"Quantity\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"Objects\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "llama2 = models.LlamaCpp(\"./mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf\")\n",
    "\n",
    "@guidance\n",
    "def generate_room_design(lm, description, n_items=4):\n",
    "    lm += f'''{{\n",
    "        \"Objects\": [\n",
    "            {\", \".join([\n",
    "                f\"\"\"{{\n",
    "                    \"Object name\": \"{gen('object_name_' + str(i), stop='\"')}\",\n",
    "                    \"Architecture style\": \"{select(['modern', 'traditional', 'industrial'], name='architecture_style_' + str(i))}\",\n",
    "                    \"Material\": \"{select(['wood', 'metal', 'glass'], name='material_' + str(i))}\",\n",
    "                    \"Bounding box size in meters\": {{\n",
    "                        \"Length\": {gen('length_' + str(i), regex='[0-9]+(.[0-9]+)?')},\n",
    "                        \"Width\": {gen('width_' + str(i), regex='[0-9]+(.[0-9]+)?')},\n",
    "                        \"Height\": {gen('height_' + str(i), regex='[0-9]+(.[0-9]+)?')}\n",
    "                    }},\n",
    "                    \"Quantity\": {gen('quantity_' + str(i), regex='[1-9][0-9]*')}\n",
    "                }}\"\"\" for i in range(n_items)\n",
    "            ])}\n",
    "        ]\n",
    "    }}'''\n",
    "\n",
    "    return lm\n",
    "\n",
    "\n",
    "\n",
    "generation = llama2 + generate_room_design(\n",
    "    \"Design a modern large living room with dimensions (10m x 10m x 6m). Suggest 4 essential objects for this room.\"\n",
    ")\n",
    "start_time = time.time()\n",
    "generated_json_text = generation.__str__()\n",
    "print(\"Generated JSON String:\")\n",
    "print(generated_json_text)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Generation took {elapsed_time:.2f} seconds to complete.\")\n",
    "\n",
    "try:\n",
    "    generated_json = json.loads(generated_json_text)\n",
    "    validate(instance=generated_json, schema=design_schema)\n",
    "    print(\"Generated JSON is valid:\")\n",
    "    print(json.dumps(generated_json, indent=4))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse as JSON.\")\n",
    "except ValidationError as e:\n",
    "    print(\"Generated JSON is invalid:\")\n",
    "    print(e.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3e50f",
   "metadata": {},
   "source": [
    "### Valid json,but... Requires a lot of time (generate 1 line in 3 minutes) and results in poor quality answers, with items like a ball, a box in the room, and a metal chair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09be95b",
   "metadata": {},
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23bd0a0",
   "metadata": {},
   "source": [
    "### Using Llana cpp and grammar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b0881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GBNF Grammar for DesignSchema\n",
    "\n",
    "# root ::= \"{\" objects \"}\"\n",
    "\n",
    "# objects ::= '\"Objects\": [' room_object (\", \" room_object)* ']'\n",
    "\n",
    "# room_object ::= \"{ \" object_name \", \" architecture_style \", \" material \", \" bounding_box \", \" quantity \" }\"\n",
    "\n",
    "# object_name ::= '\"Object name\": \"' TEXT '\"'\n",
    "# architecture_style ::= '\"Architecture style\": ' architecture_enum\n",
    "# material ::= '\"Material\": ' material_enum\n",
    "# bounding_box ::= '\"Bounding box size in meters\": { \"Length\": ' NUMBER ', \"Width\": ' NUMBER ', \"Height\": ' NUMBER ' }'\n",
    "# quantity ::= '\"Quantity\": ' INT\n",
    "\n",
    "# architecture_enum ::= '\"modern\"' | '\"traditional\"' | '\"industrial\"'\n",
    "# material_enum ::= '\"wood\"' | '\"metal\"' | '\"glass\"'\n",
    "\n",
    "# # Define basic data types\n",
    "# TEXT ::= [a-zA-Z0-9 ]+\n",
    "# NUMBER ::= [0-9]+ (\".\" [0-9]+)?\n",
    "# INT ::= [1-9][0-9]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c670ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from ./mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = nondzu_mistral-7b-instruct-v0.2-code-ft\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 3\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = nondzu_mistral-7b-instruct-v0.2-code-ft\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 2 '</s>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4892.99 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: n_batch    = 1024\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   128.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    98.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'nondzu_mistral-7b-instruct-v0.2-code-ft', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "grammar_path = \"./design_schema.gbnf\"\n",
    "llm = Llama(\n",
    "    model_path=\"./mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf\",\n",
    "    n_gpu_layers=-1,   \n",
    "    n_batch=1024,       \n",
    "    f16_kv=True,        \n",
    "    n_ctx=1024,         \n",
    "    grammar_path=grammar_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f773a8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =  134982.17 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   252 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   771 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  278499.49 ms /  1023 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model:\n",
      "{'id': 'chatcmpl-59b78654-1321-46cb-ab57-96e02f574cd2', 'object': 'chat.completion', 'created': 1731571583, 'model': './mistral-7b-instruct-v0.2-code-ft.Q5_K_M.gguf', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': ' Here is a JSON representation for four essential objects based on the modern style, the room size and user needs.\\n\\n```json\\n{\\n    \"Objects\": [\\n        {\\n            \"Object name\": \"Modern Sofa Set\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"leather\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 3.0,\\n                \"Width\": 3.0,\\n                \"Height\": 1.0\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Minimalist Coffee Table\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"glass\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 2.0,\\n                \"Width\": 2.0,\\n                \"Height\": 0.7\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Contemporary Book Shelf\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"wood\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 4.0,\\n                \"Width\": 1.0,\\n                \"Height\": 3.0\\n            },\\n            \"Quantity\": 1\\n        },\\n        {\\n            \"Object name\": \"Abstract Artwork\",\\n            \"Architecture style\": \"modern\",\\n            \"Material\": \"canvas\",\\n            \"Bounding box size in meters\": {\\n                \"Length\": 1.5,\\n                \"Width\": 1.5,\\n                \"Height\": 2.0\\n            },\\n            \"Quantity\": 1\\n        }\\n    ]\\n}\\n```\\nThis JSON object contains the descriptions, materials, dimensions, and quantities of four suggested modern objects for the large living room. The objects include a modern sofa set, a minimalist coffee table, a contemporary book shelf, and an abstract artwork. Please adjust the dimensions and the quantity according to your specific requirements. \\n\\nPlease note that the bounding box size represents the physical size of the object and does not account for any projection or protrusion from the wall or other objects. This is an approximation and can vary based on the product model. Always check the detailed product specifications before purchasing. \\n\\nThese objects are chosen based on the assumption of a living room being a space for relaxation and entertainment. A sofa set provides seating for visitors or family members. A coffee table provides a space for placing items and drinks. A book shelf is handy for keeping books, decorative items, and other knickknacks. Abstract artwork adds a touch of modern aesthetics and personality to the room. \\n\\nThis is a basic solution. Depending on your specific needs (like having children, preferred material, etc.), the selection might change. \\n\\nRemember that the overall look and feel of these items depend on the color scheme, texture, and the existing decor of your modern large living room. \\n\\nBefore buying and placing the suggested objects, consider the room\\'s existing furniture layout, color palette, and the function of each area in the living room. \\n\\nAlso, professional interior designers might suggest a different combination based on the actual room\\'s layout, your personal preferences, and the existing furniture and decorations. \\n\\nPlease ensure these objects fit within the room dimensions and your personal taste. Consider consulting a professional'}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 252, 'completion_tokens': 772, 'total_tokens': 1024}}\n",
      "Extracted JSON text:\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Modern Sofa Set\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 3.0,\n",
      "                \"Height\": 1.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Minimalist Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.0,\n",
      "                \"Width\": 2.0,\n",
      "                \"Height\": 0.7\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Contemporary Book Shelf\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 4.0,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 3.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Abstract Artwork\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"canvas\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.5,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Generated JSON:\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Modern Sofa Set\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 3.0,\n",
      "                \"Height\": 1.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Minimalist Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.0,\n",
      "                \"Width\": 2.0,\n",
      "                \"Height\": 0.7\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Contemporary Book Shelf\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 4.0,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 3.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Abstract Artwork\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"canvas\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.5,\n",
      "                \"Height\": 2.0\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Generated JSON is invalid:\n",
      "'Object Name' is a required property\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "design_schema  = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Objects\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Object Name\": {\"type\": \"string\"},\n",
    "                    \"Architecture Style\": {\"type\": \"string\"},\n",
    "                    \"Material\": {\"type\": \"string\"},\n",
    "                    \"Bounding Box Size\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"Length\": {\"type\": \"number\"},\n",
    "                            \"Width\": {\"type\": \"number\"},\n",
    "                            \"Height\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"Length\", \"Width\", \"Height\"]\n",
    "                    },\n",
    "                    \"Quantity\": {\"type\": \"integer\", \"minimum\": 1}\n",
    "                },\n",
    "                \"required\": [\"Object Name\", \"Architecture Style\", \"Material\", \"Bounding Box Size\", \"Quantity\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"Objects\"]\n",
    "}\n",
    "test_prompt = \"\"\"\n",
    "Design a modern large living room with dimensions (10m x 10m x 6m). \n",
    "Suggest 4 essential objects based on the room size, style, and user needs.\n",
    "\n",
    "Respond with a JSON array of objects, each including:\n",
    "- \"Object name\"\n",
    "- \"Architecture style\" (modern, traditional, industrial)\n",
    "- \"Material\" (wood, metal, glass)\n",
    "- \"Bounding box size in meters\" (Length, Width, Height)\n",
    "- \"Quantity\"\n",
    "\n",
    "Respond strictly in the following JSON format:\n",
    "{\n",
    "    \"Objects\": [\n",
    "        {\n",
    "            \"Object name\": \"Sample Object\",\n",
    "            \"Architecture style\": \"modern\",\n",
    "            \"Material\": \"wood\",\n",
    "            \"Bounding box size in meters\": {\n",
    "                \"Length\": 1.0,\n",
    "                \"Width\": 1.0,\n",
    "                \"Height\": 1.0\n",
    "            },\n",
    "            \"Quantity\": 1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Ensure JSON format is complete and within token limits.\n",
    "\"\"\"\n",
    "\n",
    "response = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that responds strictly in JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": test_prompt}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024  \n",
    ")\n",
    "\n",
    "print(\"Response from model:\")\n",
    "print(response)\n",
    "\n",
    "try:\n",
    "    generated_text = response.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    \n",
    "    if not generated_text:\n",
    "        raise KeyError(\"Response content not found.\")\n",
    "\n",
    "    start_index = generated_text.find('{')\n",
    "    end_index = generated_text.rfind('}') + 1\n",
    "    extracted_json_text = generated_text[start_index:end_index]\n",
    "    print(\"Extracted JSON text:\")\n",
    "    print(extracted_json_text)\n",
    "\n",
    "    generated_json = json.loads(extracted_json_text)\n",
    "    print(\"Generated JSON:\")\n",
    "    print(json.dumps(generated_json, indent=4))\n",
    "    validate(instance=generated_json, schema=design_schema)\n",
    "    print(\"Generated JSON is valid.\")\n",
    "    \n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse as JSON. Output was likely incomplete or not in JSON format.\")\n",
    "except ValidationError as e:\n",
    "    print(\"Generated JSON is invalid:\")\n",
    "    print(e.message)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6160cf",
   "metadata": {},
   "source": [
    "### Invalid json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e45be",
   "metadata": {},
   "source": [
    "## Experiment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36619a2",
   "metadata": {},
   "source": [
    "### Using GigaChat-Pro-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14ec093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token: eyJjdHkiOiJqd3QiLCJlbmMiOiJBMjU2Q0JDLUhTNTEyIiwiYWxnIjoiUlNBLU9BRVAtMjU2In0.AT0Ao3XuwSfAz0b_5Bpax7-Li_6DvYx_8_haIBQm76Z3DgUv6V24W07QZJ7uxcQyt_Ys0gKDDbfuzayO2DBOdj4Rn63aF2kAsLDaeSpZS_WDNC_n7Cgq6MNKzIPMYZ8j5oWvOkASAoItFmMZBLvgYkKKRJX6iVMaOx0gj7YqmJYTkK0b4enp_MplUGAl_qZ-OydKdmloHjo4mralUHnYUA66yNquM1mY1bYNs4DinLpccDJSG_xmzQYKx_JWo4fPo2VIzxTOqCFH1K5J4pa1KkXmVxgAl9tIp_Q1vrAeXqtGiqxnAbEwFgC3zdF0WOy41EbnOHAa9bSs1d6SLFMQcA.rKQ5KbhcY1QIcTLlJviYEg.6BtNsIIkgBmTamP_xm2k02fDiYFoJgtxx4a7MIShhOPf3BNgEgSTXOl2Tjh7WYIQ-oHI_k_GRqG_c8QWvC9xZLYlQZRud0M9vvcjD9QfUGtz9AxgvqAggDlWAYICK8qiAynElkCQtGldCiFnJYM4t31gGNbEd_Q0QMY68hS55XUKWGyMP94weXUe1lL3v8mMiJgCTRYnIquqytokvySoZ9E6CvU6bYmqkhPxZEYXDWNVcq5qCNyZnMHCwfNpQfM3vJHSgqSm2exd_gKhT67WOoAlIotkBESK-pqiZc4mfSWw9CWp9P7Jk6gPE8u17u-xmymQ58JAxaVtJ9-5BxrNvCunrPXIC_UqBSt9UQd3S9SES50eQVfcOIh64LZeG2GmRCF51GLL7XsIzTrUs6mB6eIBq8j7ZQXin5yXRcAMydBfLeObMUsmLSwe1xZyQzlR9GL6_PmOczwYNn_M3KLDR94klZ95CuYGw71eBCWN0pL0pRMOHK1bfSM5Sueul4dFVUdundkriEXX4UTa-hFYwsEDW5Uln1n3VKtblP3rgXD4RzB-ZVUfZ0DSomofcn_RLJHfV2Pv1TrgbKw1W-4OBtu3ao949gaL0xoshEx_UzokZpxHvTGicV0nRYKDagWLbPtizBTLNQnmOy5Vdlf0HojWRwWOgfE6IX1BBgX-k_9_emXyLK7jPuZT4UKR0Mf76Nj3DUyOfv2CC6plLdCyiSLkj0N9-BwWrEZyVzaT79k.jz4soA2s8Ht8CBcv4712gHQACuoxsPb8--hXGZBq_dU\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import uuid\n",
    "import base64\n",
    "import warnings\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "\n",
    "client_id = \"0c0728ba-647e-4329-a618-975eaf7dd514\"\n",
    "client_secret = \"340fcdd9-e53b-4d7b-b3b5-e638da8f4cc6\"\n",
    "authorization_key = \"MGMwNzI4YmEtNjQ3ZS00MzI5LWE2MTgtOTc1ZWFmN2RkNTE0OjM0MGZjZGQ5LWU1M2ItNGQ3Yi1iM2I1LWU2MzhkYThmNGNjNg==\"\n",
    "\n",
    "oauth_url = \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\"\n",
    "\n",
    "# generate a unique RqUID for the request\n",
    "rq_uid = str(uuid.uuid4())\n",
    "\n",
    "payload = {\n",
    "    'scope': 'GIGACHAT_API_CORP',\n",
    "    'grant_type': 'client_credentials'\n",
    "}\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'Accept': 'application/json',\n",
    "    'RqUID': rq_uid,\n",
    "    'Authorization': f'Basic {authorization_key}'\n",
    "}\n",
    "\n",
    "# request to obtain the access token\n",
    "response = requests.post(oauth_url, headers=headers, data=payload, verify=False)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    access_token = response.json().get(\"access_token\")\n",
    "    print(\"Access token:\", access_token)\n",
    "else:\n",
    "    print(f\"Failed to obtain access token: {response.status_code}\")\n",
    "    print(\"Response:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d759f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"eyJjdHkiOiJqd3QiLCJlbmMiOiJBMjU2Q0JDLUhTNTEyIiwiYWxnIjoiUlNBLU9BRVAtMjU2In0.AT0Ao3XuwSfAz0b_5Bpax7-Li_6DvYx_8_haIBQm76Z3DgUv6V24W07QZJ7uxcQyt_Ys0gKDDbfuzayO2DBOdj4Rn63aF2kAsLDaeSpZS_WDNC_n7Cgq6MNKzIPMYZ8j5oWvOkASAoItFmMZBLvgYkKKRJX6iVMaOx0gj7YqmJYTkK0b4enp_MplUGAl_qZ-OydKdmloHjo4mralUHnYUA66yNquM1mY1bYNs4DinLpccDJSG_xmzQYKx_JWo4fPo2VIzxTOqCFH1K5J4pa1KkXmVxgAl9tIp_Q1vrAeXqtGiqxnAbEwFgC3zdF0WOy41EbnOHAa9bSs1d6SLFMQcA.rKQ5KbhcY1QIcTLlJviYEg.6BtNsIIkgBmTamP_xm2k02fDiYFoJgtxx4a7MIShhOPf3BNgEgSTXOl2Tjh7WYIQ-oHI_k_GRqG_c8QWvC9xZLYlQZRud0M9vvcjD9QfUGtz9AxgvqAggDlWAYICK8qiAynElkCQtGldCiFnJYM4t31gGNbEd_Q0QMY68hS55XUKWGyMP94weXUe1lL3v8mMiJgCTRYnIquqytokvySoZ9E6CvU6bYmqkhPxZEYXDWNVcq5qCNyZnMHCwfNpQfM3vJHSgqSm2exd_gKhT67WOoAlIotkBESK-pqiZc4mfSWw9CWp9P7Jk6gPE8u17u-xmymQ58JAxaVtJ9-5BxrNvCunrPXIC_UqBSt9UQd3S9SES50eQVfcOIh64LZeG2GmRCF51GLL7XsIzTrUs6mB6eIBq8j7ZQXin5yXRcAMydBfLeObMUsmLSwe1xZyQzlR9GL6_PmOczwYNn_M3KLDR94klZ95CuYGw71eBCWN0pL0pRMOHK1bfSM5Sueul4dFVUdundkriEXX4UTa-hFYwsEDW5Uln1n3VKtblP3rgXD4RzB-ZVUfZ0DSomofcn_RLJHfV2Pv1TrgbKw1W-4OBtu3ao949gaL0xoshEx_UzokZpxHvTGicV0nRYKDagWLbPtizBTLNQnmOy5Vdlf0HojWRwWOgfE6IX1BBgX-k_9_emXyLK7jPuZT4UKR0Mf76Nj3DUyOfv2CC6plLdCyiSLkj0N9-BwWrEZyVzaT79k.jz4soA2s8Ht8CBcv4712gHQACuoxsPb8--hXGZBq_dU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4906c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_url = \"https://gigachat-preview.devices.sberbank.ru/api/v1/chat/completions\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': f'Bearer {access_token}'\n",
    "}\n",
    "payload = {\n",
    "    \"model\": \"GigaChat-Pro-preview\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Ты профессиональный переводчик на английский язык. Переведи точно сообщение пользователя.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Привет, меня зовут Яна, я люблю дата сайенс\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"update_interval\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b90a089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from GigaChat API:\n",
      "```json\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Large Sectional Sofa\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"fabric\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 2.5,\n",
      "                \"Height\": 1.2\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Glass Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 0.7\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Metal Bookshelf\",\n",
      "            \"Architecture style\": \"industrial\",\n",
      "            \"Material\": \"metal\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.0,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 1.8\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"LED TV Stand\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 0.7\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Generated JSON is valid:\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Large Sectional Sofa\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"fabric\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 2.5,\n",
      "                \"Height\": 1.2\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Glass Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 0.7\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Metal Bookshelf\",\n",
      "            \"Architecture style\": \"industrial\",\n",
      "            \"Material\": \"metal\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 2.0,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 1.8\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"LED TV Stand\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 0.7\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Generation took 0.01 seconds to complete.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "import time\n",
    "\n",
    "design_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Objects\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Object name\": {\"type\": \"string\"},\n",
    "                    \"Architecture style\": {\"type\": \"string\", \"enum\": [\"modern\", \"traditional\", \"industrial\"]},\n",
    "                    \"Material\": {\"type\": \"string\"},\n",
    "                    \"Bounding box size in meters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"Length\": {\"type\": \"number\"},\n",
    "                            \"Width\": {\"type\": \"number\"},\n",
    "                            \"Height\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"Length\", \"Width\", \"Height\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"Quantity\": {\"type\": \"integer\", \"minimum\": 1}\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"Object name\", \"Architecture style\", \"Material\",\n",
    "                    \"Bounding box size in meters\", \"Quantity\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"Objects\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "test_prompt = \"\"\"\n",
    "Design a modern large living room with dimensions (10m x 10m x 6m). \n",
    "Suggest 4 essential objects based on the room size, style, and user needs.\n",
    "\n",
    "Respond with a JSON array of objects, each including:\n",
    "- \"Object name\"\n",
    "- \"Architecture style\" (one from: modern, traditional, industrial)\n",
    "- \"Material\" (one from: wood, metal, glass)\n",
    "- \"Bounding box size in meters\" (Length, Width, Height)\n",
    "- \"Quantity\"\n",
    "\n",
    "Respond strictly in the following JSON format:\n",
    "{\n",
    "    \"Objects\": [\n",
    "        {\n",
    "            \"Object name\": \"Sample Object\",\n",
    "            \"Architecture style\": \"modern\",\n",
    "            \"Material\": \"wood\",\n",
    "            \"Bounding box size in meters\": {\n",
    "                \"Length\": 1.0,\n",
    "                \"Width\": 1.0,\n",
    "                \"Height\": 1.0\n",
    "            },\n",
    "            \"Quantity\": 1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Ensure JSON format is complete and within token limits.\n",
    "\"\"\"\n",
    "\n",
    "chat_url = \"https://gigachat-preview.devices.sberbank.ru/api/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': f'Bearer {access_token}'\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"GigaChat-Pro-preview\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that outputs in JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": test_prompt}\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"update_interval\": 0\n",
    "}\n",
    "\n",
    "response = requests.post(chat_url, headers=headers, json=payload, verify=False)\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    response_data = response.json()\n",
    "    generated_text = response_data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    print(\"Response from GigaChat API:\")\n",
    "    print(generated_text)\n",
    "\n",
    "    # Extract JSON from the response \n",
    "    start_index = generated_text.find('{')\n",
    "    end_index = generated_text.rfind('}') + 1\n",
    "    extracted_json_text = generated_text[start_index:end_index]\n",
    "\n",
    "    generated_json = json.loads(extracted_json_text)\n",
    "    validate(instance=generated_json, schema=design_schema)\n",
    "    print(\"Generated JSON is valid:\")\n",
    "    print(json.dumps(generated_json, indent=4))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Generation took {elapsed_time:.2f} seconds to complete.\")\n",
    "\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to parse as JSON\")\n",
    "except ValidationError as e:\n",
    "    print(\"Generated JSON is invalid:\")\n",
    "    print(e.message)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55993481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "{'object': 'list', 'data': [{'id': 'DeepSeek-R1', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-2', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-2-Max', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-2-Max-preview', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-2-Pro', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-2-Pro-preview', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-2-preview', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-Max', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-Max-preview', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-Plus', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-Plus-preview', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-Pro', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-Pro-preview', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaChat-preview', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'chat'}, {'id': 'GigaCheckClassification', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'aicheck'}, {'id': 'GigaCheckDetection', 'object': 'model', 'owned_by': 'salutedevices', 'type': 'aicheck'}]}\n"
     ]
    }
   ],
   "source": [
    "models_url = \"https://gigachat-preview.devices.sberbank.ru/api/v1/models\"\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': f'Bearer {access_token}'\n",
    "}\n",
    "\n",
    "response = requests.get(models_url, headers=headers, verify=False)\n",
    "models_list = response.json()\n",
    "print(\"Available models:\")\n",
    "print(models_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e58942",
   "metadata": {},
   "source": [
    "## Experiment 6. Using GigaChat-Max-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90c0f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from GigaChat API:\n",
      "```json\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Sectional Sofa\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.5,\n",
      "                \"Width\": 2.5,\n",
      "                \"Height\": 0.8\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 0.45\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Floor Lamp\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"metal\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 0.25,\n",
      "                \"Width\": 0.25,\n",
      "                \"Height\": 1.7\n",
      "            },\n",
      "            \"Quantity\": 2\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Entertainment Unit\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 0.5,\n",
      "                \"Height\": 0.9\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Generation took 6.93 seconds to complete.\n",
      "Generated JSON is valid:\n",
      "{\n",
      "    \"Objects\": [\n",
      "        {\n",
      "            \"Object name\": \"Sectional Sofa\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"leather\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.5,\n",
      "                \"Width\": 2.5,\n",
      "                \"Height\": 0.8\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Coffee Table\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"glass\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 1.5,\n",
      "                \"Width\": 1.0,\n",
      "                \"Height\": 0.45\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Floor Lamp\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"metal\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 0.25,\n",
      "                \"Width\": 0.25,\n",
      "                \"Height\": 1.7\n",
      "            },\n",
      "            \"Quantity\": 2\n",
      "        },\n",
      "        {\n",
      "            \"Object name\": \"Entertainment Unit\",\n",
      "            \"Architecture style\": \"modern\",\n",
      "            \"Material\": \"wood\",\n",
      "            \"Bounding box size in meters\": {\n",
      "                \"Length\": 3.0,\n",
      "                \"Width\": 0.5,\n",
      "                \"Height\": 0.9\n",
      "            },\n",
      "            \"Quantity\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "chat_url = \"https://gigachat-preview.devices.sberbank.ru/api/v1/chat/completions\"\n",
    "\n",
    "design_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"Objects\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Object name\": {\"type\": \"string\"},\n",
    "                    \"Architecture style\": {\"type\": \"string\", \"enum\": [\"modern\", \"traditional\", \"industrial\"]},\n",
    "                    \"Material\": {\"type\": \"string\"},\n",
    "                    \"Bounding box size in meters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"Length\": {\"type\": \"number\"},\n",
    "                            \"Width\": {\"type\": \"number\"},\n",
    "                            \"Height\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"Length\", \"Width\", \"Height\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"Quantity\": {\"type\": \"integer\", \"minimum\": 1}\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"Object name\", \"Architecture style\", \"Material\",\n",
    "                    \"Bounding box size in meters\", \"Quantity\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"Objects\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "test_prompt = \"\"\"\n",
    "Design a modern large living room with dimensions (10m x 10m x 6m). \n",
    "Suggest 4 essential objects based on the room size, style, and user needs.\n",
    "\n",
    "Respond with a JSON array of objects, each including:\n",
    "- \"Object name\"\n",
    "- \"Architecture style\" (modern, traditional, industrial)\n",
    "- \"Material\" (wood, metal, glass)\n",
    "- \"Bounding box size in meters\" (Length, Width, Height)\n",
    "- \"Quantity\"\n",
    "\n",
    "Respond strictly in the following JSON format:\n",
    "{\n",
    "    \"Objects\": [\n",
    "        {\n",
    "            \"Object name\": \"Sample Object\",\n",
    "            \"Architecture style\": \"modern\",\n",
    "            \"Material\": \"wood\",\n",
    "            \"Bounding box size in meters\": {\n",
    "                \"Length\": 1.0,\n",
    "                \"Width\": 1.0,\n",
    "                \"Height\": 1.0\n",
    "            },\n",
    "            \"Quantity\": 1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Ensure JSON format is complete and within token limits.\n",
    "\"\"\"\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': f'Bearer {access_token}'\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"GigaChat-Max-preview\",  \n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that outputs in JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": test_prompt}\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"update_interval\": 0\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "response = requests.post(chat_url, headers=headers, json=payload, verify=False)\n",
    "response_data = response.json()\n",
    "generated_text = response_data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "print(\"Response from GigaChat API:\")\n",
    "print(generated_text)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Generation took {elapsed_time:.2f} seconds to complete.\")\n",
    "\n",
    "start_index = generated_text.find('{')\n",
    "end_index = generated_text.rfind('}') + 1\n",
    "extracted_json_text = generated_text[start_index:end_index]\n",
    "\n",
    "generated_json = json.loads(extracted_json_text)\n",
    "validate(instance=generated_json, schema=design_schema)\n",
    "print(\"Generated JSON is valid:\")\n",
    "print(json.dumps(generated_json, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96531b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bedcb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d9829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20ad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb76faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-idesign]",
   "language": "python",
   "name": "conda-env-miniconda-idesign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
