{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89469f1f-1e49-420f-a339-a616ba6f48ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_HOME = /home/jovyan/shares/SR008.fs2/iana_kulichenko/cuda-12.4\n",
      "PATH = /home/jovyan/shares/SR008.fs2/iana_kulichenko/cuda-12.4/bin:/home/jovyan/.mlspace/envs/deepseek_iana/bin:/home/jovyan/.mlspace/envs/deepseek_iana/bin:/home/user/conda/condabin:/home/user/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/user/conda/bin\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Tue_Feb_27_16:19:38_PST_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.99\n",
      "Build cuda_12.4.r12.4/compiler.33961263_0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] = \"/home/jovyan/.mlspace/envs/deepseek_iana/bin:\" + os.environ[\"PATH\"]\n",
    "os.environ[\"CUDA_HOME\"] = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/cuda-12.4\"\n",
    "os.environ[\"PATH\"] = os.path.join(os.environ[\"CUDA_HOME\"], \"bin\") + \":\" + os.environ[\"PATH\"]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"CUDA_HOME =\", os.environ[\"CUDA_HOME\"])\n",
    "print(\"PATH =\", os.environ[\"PATH\"])\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083d6f2e-1bff-4010-9273-27e59e10cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "# from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff44985-5d03-4736-9924-9073bbe982c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244a9edf-89c4-44e0-952c-46fc60658cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d3fe62b6194570932a18c7b9eee81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Result ===\n",
      "### Ratings:\n",
      "- Ergonomic & Functional Placements: 0.7\n",
      "- Visual Harmony and Aesthetics: 0.6\n",
      "- Proportionality and Scale: 0.8\n",
      "- Readiness to Pay: 0.5\n",
      "\n",
      "### Suggestions:\n",
      "- Move the Wardrobe closer to the center of the room for better balance.\n",
      "- Position the Desk Perturber near the Desk to facilitate interaction.\n",
      "- Adjust the Coffee Table slightly further from the Chair for better space utilization.\n",
      "- Reorient the Desk to align more closely with the North Wall for improved ergonomics.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "image_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2\"\n",
    "eval_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/evaluations\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "image_files = [\n",
    "    os.path.join(image_dir, f)\n",
    "    for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "if not image_files:\n",
    "    raise ValueError(\"No image files found in the specified folder.\")\n",
    "img_path = image_files[0]\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\", use_fast=True)\n",
    "evaluation_instruction = (\n",
    "    \"As a professional interior designer, evaluate the following 2D layout visually. \"\n",
    "    \"Provide exactly four ratings (each a number between 0 and 1) based on:\\n\\n\"\n",
    "    \"- Ergonomic & Functional Placements: Comfort, accessibility, and practicality.\\n\"\n",
    "    \"- Visual Harmony and Aesthetics: Balance and overall appeal.\\n\"\n",
    "    \"- Proportionality and Scale: Correct sizes, rotations, and proportions.\\n\"\n",
    "    \"- Readiness to Pay: Value assessment (1 = willing to purchase, 0 = not).\\n\\n\"\n",
    "    \"Also, list up to three one-sentence suggestions for coordinate adjustments under 'Suggestions'. \"\n",
    "    \"Do not propose adding or removing objects; only recommend repositioning the existing items.\\n\\n\"\n",
    "    \"Output exactly as:\\n\"\n",
    "    \"### Ratings:\\n\"\n",
    "    \"- Ergonomic & Functional Placements: <rating>\\n\"\n",
    "    \"- Visual Harmony and Aesthetics: <rating>\\n\"\n",
    "    \"- Proportionality and Scale: <rating>\\n\"\n",
    "    \"- Readiness to Pay: <rating>\\n\"\n",
    "    \"### Suggestions:\\n\"\n",
    "    \"- <suggestion 1>\\n\"\n",
    "    \"- <suggestion 2>\\n\"\n",
    "    \"- <suggestion 3>\\n\\n\"\n",
    "    \"Replace <rating> with a number between 0 and 1, and each <suggestion> with a brief recommendation.\"\n",
    ")\n",
    "\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"image\", \"image\": image},\n",
    "        {\"type\": \"text\", \"text\": evaluation_instruction}\n",
    "    ]\n",
    "}\n",
    "\n",
    "messages = [message]\n",
    "\n",
    "text_prompt = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "image_inputs, _ = process_vision_info(messages)\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt],\n",
    "    images=image_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(model.device)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=1300)\n",
    "\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(inputs.input_ids[0]):] for out_ids in generated_ids\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "evaluation_result = output_text[0]\n",
    "print(\"=== Evaluation Result ===\")\n",
    "print(evaluation_result)\n",
    "\n",
    "eval_file_path = os.path.join(eval_dir, \"1.txt\")\n",
    "with open(eval_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45480ce-1ec2-40c2-8e54-63a0c4bea396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017fc0e-9c48-4349-8436-ad87c7d8441b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0226216c-107f-4f0b-bf27-72d4294adf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f19d6e-1f79-40ef-ba6c-e9d636aa4604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb663d91e4a4c12bfe999efa33c9ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/1.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/3.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/4.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/5.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/6.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/8.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/9.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/10.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/11.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/12.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/13.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/14.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/15.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/16.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/17.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/18.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/19.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/20.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/21.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/22.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/23.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/24.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/25.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/26.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/27.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/28.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/29.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/30.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/31.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/32.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/33.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/34.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/35.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/36.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/37.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/38.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/39.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/40.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/41.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/42.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/43.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/44.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/45.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/46.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/47.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/48.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/49.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/50.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/52.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/53.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/54.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/55.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/56.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/57.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/58.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/59.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/60.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/61.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/62.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/63.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/64.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/65.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/66.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/67.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/68.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/69.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/70.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/71.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/72.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/73.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/74.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/75.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/76.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/77.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/78.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/79.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/80.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/81.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/82.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/83.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/84.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/86.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/87.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/88.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/89.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/90.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/92.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/93.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/94.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/95.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/96.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/97.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/98.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/99.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/100.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "image_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2\"\n",
    "eval_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/evaluations\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "image_files = [\n",
    "    os.path.join(image_dir, f)\n",
    "    for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "def extract_number(filepath):\n",
    "    base = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    return int(base)\n",
    "\n",
    "sorted_files = sorted(image_files, key=extract_number)\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-72B-Instruct\", use_fast=False)\n",
    "\n",
    "evaluation_instruction = (\n",
    "    \"As a professional interior designer, evaluate the following 2D layout visually. \"\n",
    "    \"Provide exactly four ratings (each a number between 0 and 1) based on:\\n\\n\"\n",
    "    \"- Ergonomic & Functional Placements: Comfort, accessibility, and practicality.\\n\"\n",
    "    \"- Visual Harmony and Aesthetics: Balance and overall appeal.\\n\"\n",
    "    \"- Proportionality and Scale: Correct sizes, rotations, and proportions.\\n\"\n",
    "    \"- Readiness to Pay: Value assessment (1 = willing to purchase, 0 = not).\\n\\n\"\n",
    "    \"Also, list up to three one-sentence suggestions for coordinate adjustments under 'Suggestions'.\\n\\n\"\n",
    "    \"Output exactly as:\\n\"\n",
    "    \"### Ratings:\\n\"\n",
    "    \"- Ergonomic & Functional Placements: <rating>\\n\"\n",
    "    \"- Visual Harmony and Aesthetics: <rating>\\n\"\n",
    "    \"- Proportionality and Scale: <rating>\\n\"\n",
    "    \"- Readiness to Pay: <rating>\\n\"\n",
    "    \"### Suggestions:\\n\"\n",
    "    \"- <suggestion 1>\\n\"\n",
    "    \"- <suggestion 2>\\n\"\n",
    "    \"- <suggestion 3>\\n\\n\"\n",
    "    \"Replace <rating> with a number between 0 and 1, and each <suggestion> with a brief recommendation.\"\n",
    ")\n",
    "\n",
    "for img_path in sorted_files:\n",
    "    print(f\"Processing image: {img_path}\")\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": evaluation_instruction}\n",
    "        ]\n",
    "    }\n",
    "    messages = [message]\n",
    "\n",
    "    text_prompt = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text_prompt],\n",
    "        images=image_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=2048)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(inputs.input_ids[0]):] for out_ids in generated_ids\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    evaluation_result = output_text[0]\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    eval_file_path = os.path.join(eval_dir, f\"{base_name}_evaluation.txt\")\n",
    "    with open(eval_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d3d91-0624-419e-9295-b838540d8bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd768be-d49a-4b0e-a819-f019955f4aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3be8d80cd1044cfad549f63eb321fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/1.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/3.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/4.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/5.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/6.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/8.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/9.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/10.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/11.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/12.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/13.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/14.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/15.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/16.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/17.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/18.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/19.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/20.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/21.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/22.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/23.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/24.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/25.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/26.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/27.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/28.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/29.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/30.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/31.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/32.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/33.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/34.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/35.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/36.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/37.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/38.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/39.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/40.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/41.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/42.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/43.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/44.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/45.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/46.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/47.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/48.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/49.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/50.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/52.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/53.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/54.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/55.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/56.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/57.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/58.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/59.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/60.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/61.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/62.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/63.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/64.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/65.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/66.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/67.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/68.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/69.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/70.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/71.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/72.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/73.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/74.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/75.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/76.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/77.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/78.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/79.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/80.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/81.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/82.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/83.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/84.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/86.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/87.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/88.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/89.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/90.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/92.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/93.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/94.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/95.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/96.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/97.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/98.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/99.png\n",
      "Processing image: /home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2/100.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "image_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2\"\n",
    "eval_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/evaluations_2\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "image_files = [\n",
    "    os.path.join(image_dir, f)\n",
    "    for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "def extract_number(filepath):\n",
    "    base = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    return int(base)\n",
    "\n",
    "sorted_files = sorted(image_files, key=extract_number)\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-72B-Instruct\", use_fast=False)\n",
    "\n",
    "evaluation_instruction = (\n",
    "    \"As a professional designer with expertise in spatial layout and interior design, \"\n",
    "    \"please provide a comprehensive evaluation of the following 2D layout. \\n\"\n",
    "    \" Make detailed analysis, suggest in detailes how to improve and than provide answer.\\n \"\n",
    "    \"Assign exactly six ratings (each a number from 0 to 1) based on the following criteria:\\n\\n\"\n",
    "    \"- All Objects Within Room Bounds: Determine whether every object is placed fully within the room boundaries.\\n\"\n",
    "    \"- No Objects Overlap: Assess whether the objects are well-spaced and not overlap.\\n\"\n",
    "    \"- Overall Layout Quality: Evaluate the visual harmony, balance, and overall effectiveness of the design.\\n\"\n",
    "    \"- Functionality of the Layout: Assess how well the layout meets practical requirements and optimizes space usage.\\n\"\n",
    "    \"- Ergonomic Placements: Judge the positioning of elements in terms of comfort, accessibility, and user experience.\\n\"\n",
    "    \"- Readiness to Pay: Indicate whether you would consider this design valuable enough to purchase (use 1 for yes, 0 for no).\\n\"\n",
    "    \"Please ensure that the output is formatted exactly as follows:\\n\"\n",
    "    \"### Ratings:\\n\"\n",
    "    \"- All Objects Within Room Bounds: <rating>\\n\"\n",
    "    \"- Objects Not Overlap: <rating>\\n\"\n",
    "    \"- Overall Layout Quality: <rating>\\n\"\n",
    "    \"- Functionality of the Layout: <rating>\\n\"\n",
    "    \"- Ergonomic Placements: <rating>\\n\"\n",
    "    \"- Readiness to Pay: <rating>\\n\"\n",
    "    \"Replace <rating> with a number between 0 and 1.\"\n",
    ")\n",
    "\n",
    "for img_path in sorted_files:\n",
    "    print(f\"Processing image: {img_path}\")\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": evaluation_instruction}\n",
    "        ]\n",
    "    }\n",
    "    messages = [message]\n",
    "\n",
    "    text_prompt = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text_prompt],\n",
    "        images=image_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=2048)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(inputs.input_ids[0]):] for out_ids in generated_ids\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    evaluation_result = output_text[0]\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    eval_file_path = os.path.join(eval_dir, f\"{base_name}_evaluation.txt\")\n",
    "    with open(eval_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc752b-08bf-40c1-bc82-91907567e817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1050d3-81c8-4edb-9965-877cd00133be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356743c-2d7a-464b-9ceb-b470a5d56763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437f16a7-fddd-40b2-bd59-473c4a969f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae7a5340e544499807e8bc417fd7301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Result ===\n",
      "### Evaluation\n",
      "\n",
      "#### Analysis:\n",
      "The provided 2D layout represents a meeting hall measuring 8.5 meters by 4.0 meters. The layout includes five objects: a desk perturber, a wardrobe, a chair, a desk, and a coffee table. Here's a detailed analysis:\n",
      "\n",
      "1. **All Objects Within Room Bounds**: All objects appear to be placed within the room boundaries, as none of them extend beyond the dashed lines indicating the walls.\n",
      "\n",
      "2. **No Objects Overlap**: The objects do not overlap with each other, ensuring clear pathways and individual space for each item.\n",
      "\n",
      "3. **Overall Layout Quality**: The current layout lacks visual harmony and balance. The objects are scattered without a clear focal point or logical arrangement. For example, the wardrobe is placed near the center of the room, which is unusual for such an item. The chair is isolated near the north wall, and the desk is placed far from it, which may not be ideal for a meeting setup.\n",
      "\n",
      "4. **Functionality of the Layout**: The functionality is suboptimal. A meeting hall typically requires a central area for discussions, but the current layout does not facilitate this. The desk and chair should ideally be positioned together to create a workspace. The coffee table is also misplaced, as it is not near any seating area.\n",
      "\n",
      "5. **Ergonomic Placements**: The ergonomic placements are poor. The chair is too far from the desk, making it inconvenient for someone to use both. The coffee table is also not easily accessible from any seating area. The wardrobe placement in the middle of the room can obstruct movement and does not serve a practical purpose in a meeting hall.\n",
      "\n",
      "6. **Readiness to Pay**: Given the issues mentioned above, this design would not be considered valuable enough to purchase in its current state.\n",
      "\n",
      "#### Suggestions for Improvement:\n",
      "- Move the wardrobe to a corner or along one of the walls to free up central space.\n",
      "- Position the desk and chair together to create a functional workspace.\n",
      "- Place the coffee table near the seating area for easy access.\n",
      "- Consider adding more seating options around the coffee table to accommodate meetings.\n",
      "- Ensure there is a clear pathway through the room for easy movement.\n",
      "- Arrange the objects in a way that creates a focal point and visual harmony.\n",
      "\n",
      "### Ratings:\n",
      "- All Objects Within Room Bounds: 1\n",
      "- Objects Not Overlap: 1\n",
      "- Overall Layout Quality: 0.3\n",
      "- Functionality of the Layout: 0.4\n",
      "- Ergonomic Placements: 0.3\n",
      "- Readiness to Pay: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "image_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/images_2\"\n",
    "eval_dir = \"/home/jovyan/shares/SR008.fs2/iana_kulichenko/Experiments/train_GRPO/evaluations\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "image_files = [\n",
    "    os.path.join(image_dir, f)\n",
    "    for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "if not image_files:\n",
    "    raise ValueError(\"No image files found in the specified folder.\")\n",
    "img_path = image_files[0]\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-72B-Instruct\", use_fast=False)\n",
    "evaluation_instruction = (\n",
    "    \"As a professional designer with expertise in spatial layout and interior design, \"\n",
    "    \"please provide a comprehensive evaluation of the following 2D layout. \\n\"\n",
    "    \" Make detailed analysis, suggest in detailes how to improve and than provide answer.\\n \"\n",
    "    \"Assign exactly six ratings (each a number from 0 to 1) based on the following criteria:\\n\\n\"\n",
    "    \"- All Objects Within Room Bounds: Determine whether every object is placed fully within the room boundaries.\\n\"\n",
    "    \"- No Objects Overlap: Assess whether the objects are well-spaced and not overlap.\\n\"\n",
    "    \"- Overall Layout Quality: Evaluate the visual harmony, balance, and overall effectiveness of the design.\\n\"\n",
    "    \"- Functionality of the Layout: Assess how well the layout meets practical requirements and optimizes space usage.\\n\"\n",
    "    \"- Ergonomic Placements: Judge the positioning of elements in terms of comfort, accessibility, and user experience.\\n\"\n",
    "    \"- Readiness to Pay: Indicate whether you would consider this design valuable enough to purchase (use 1 for yes, 0 for no).\\n\"\n",
    "    \"Please ensure that the output is formatted exactly as follows:\\n\"\n",
    "    \"### Ratings:\\n\"\n",
    "    \"- All Objects Within Room Bounds: <rating>\\n\"\n",
    "    \"- Objects Not Overlap: <rating>\\n\"\n",
    "    \"- Overall Layout Quality: <rating>\\n\"\n",
    "    \"- Functionality of the Layout: <rating>\\n\"\n",
    "    \"- Ergonomic Placements: <rating>\\n\"\n",
    "    \"- Readiness to Pay: <rating>\\n\"\n",
    "    \"Replace <rating> with a number between 0 and 1.\"\n",
    ")\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"image\", \"image\": image},\n",
    "        {\"type\": \"text\", \"text\": evaluation_instruction}\n",
    "    ]\n",
    "}\n",
    "\n",
    "messages = [message]\n",
    "\n",
    "text_prompt = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "image_inputs, _ = process_vision_info(messages)\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt],\n",
    "    images=image_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(model.device)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=2048)\n",
    "\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(inputs.input_ids[0]):] for out_ids in generated_ids\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "evaluation_result = output_text[0]\n",
    "print(\"=== Evaluation Result ===\")\n",
    "print(evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ca973-6af5-4bb5-b613-478ccbf958ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905a0c8-14b3-462d-ab2b-642c29d4b476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-deepseek_iana]",
   "language": "python",
   "name": "conda-env-.mlspace-deepseek_iana-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
